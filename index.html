<!doctype html>
<html>
	<head>
		<meta charset="utf-8">
		<meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">

		<title>Estimating Seismic Moment Tensors based on Bayesian Machine Learning, Steinberg et al., @dgg2021</title>

		<link rel="stylesheet" href="dist/reset.css">
		<link rel="stylesheet" href="dist/reveal.css">
		<link rel="stylesheet" href="theme/pyrocko.css" id="theme">
		<script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
		<script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
		<script>
		  Reveal.initialize({
		    math: {
		      mathjax: 'https://cdn.jsdelivr.net/gh/mathjax/mathjax@2.7.8/MathJax.js',
		      config: 'TeX-AMS_HTML-full',
		      // pass other options into `MathJax.Hub.Config()`
		      TeX: { Macros: { RR: "{\\bf R}" } }
		    },
		    plugins: [ RevealMath ]
		  });
		</script>
		<!--<link rel="stylesheet" href="dist/theme/moon.css" id="theme">-->

		<!-- Theme used for syntax highlighted code -->
		<link rel="stylesheet" href="theme/highlight/gruvbox-light.css" id="highlight-theme">
	</head>
    <style>
.annot {
    font-style: italic;
    color: #ffbbaa;
    padding-left: 1em;
}

.links {
    border-top: 1px solid #665544;
    padding-top: 0.5em;
    font-size: 70%;
    color: #aaaa88;
    margin-top: 2em;
    width: 100%;
}

.links li {
    list-style-type: none;
    display: inline-block;
    margin-right:1em;
}

.links a {
    color: #aaaa88;
}

.grayout {
    opacity: 0.2; /* Real browsers */
    filter: alpha(opacity = 60); /* MSIE */
}
.narrow p
{
margin: 5px 0;
}

.narrow li
{
font-size: xx-large;
}

.narrow blockquote
{
width: 90%;
margin: 10px auto;
padding: 10px;
}

.narrow td
{
font-size: 26pt;
}

.MathJax { font-size: 0.8em !important; }

.narrow pre
{
width: 500px;
}
.editor {
    margin: 1em;
    border: 1px solid #665544;
    border-radius: 0.2em;
    background-color: #333322;
}
code.inline {
    font-size: 80%;
    background-color: #444435;
    color: #ccccaa;
}

em {
    color: #ccaa33;
}

.small {
    font-size: 70%;
}

div.fbox {
  display: flex;
  vertical-align: top;
  justify-content: space-evenly;
}

div.fitem {
    flex-grow: 1;
}

    </style>
	<body>
		<div class="reveal">
			<div class="slides">
				<section>
										<h2>Estimating Seismic Moment Tensors based on Bayesian Machine Learning</h2>
                    <p style="font-size:50%">Andreas Steinberg&sup1, Hannes Vasyura-Bathke&sup2&sup3, Peter Gaebler&sup1, Matthias Ohrnberger&sup2 and Lars Ceranna&sup1</p>
										<p style="font-size:40%">1 Bundesanstalt für Geowissenschaften und Rohstoffe (BGR), B4.3 Erdbebendienst des Bundes, Kernwaffenteststopp
											<p style="font-size:40%">2 University of Potsdam, Institute for Earth and Environmental Sciences
												<p style="font-size:40%">3 King Abdullah University of Science and Technology

							      <div class="links">
											<img src="figures/bgr.jpg" style="height: 3em;"/>
											<img src="figures/up_logo_math_2.png" style="height: 3em;"/>
											<img src="figures/seiger.jpg" style="height: 3em;"/>
											<img src="figures/ptj.jpg" style="height: 3em;"/>
                    </div>
										<aside class="notes">
											<p> Hello.</p>
										</aside>
        </section>

				<section>
						<section id="Motivation">
							<h5>Motivation</h5>
							<aside class="notes">
								<p> Today i want to present to you not only a framework for applying machine learning in seismology to determine MTs.</p>
								<p> I also want to advocate that ML does not have to be a blackbox.</p>

							</aside>
						</section>


						<section>
							<h4>Full seismic moment tensors</h4>
							<div class="fitem">
									<ul>
										<li>non-linear, non-unique inversion problem between synthetics and observed data</li>
										<li>inversion > tens of minutes, e.g. <a href="https://pyrocko.org/grond/docs/current/">Grond</a> or <a href="https://hvasbath.github.io/beat/index.html">Beat</a> </li>
										<li>Catalogs (e.g. GCMT and USGS) provide MT solutions in >hours for Mw >4.5 </li>

									</ul>
							</div>
							<img src="figures/non-linear.svg" style="height: 5em;"/>
						</section>


						<section>
							<h4><u>Fast</u> estimation of seismic moment tensors necessary for:</h4>
							<div class="fitem">
									<ul>
										<li>Earthquake early warning systems, i.e. shakemaps</li>
										<li>Physics based fore- and aftershock analysis</li>
										<li>Monitoring of geothermal stimulations</li>

									</ul>
							</div>
							<img src="figures/shakemap.jpg" style="height: 8em;"/>
						</section>


						<section>
							<h4>Machine Learning</h4>
							<div class="fitem">
									<ul>
										<li>input: images and assoicated labels</li>
										<li>learning features of by layered convolutions with kernels</li>
										<li>kernel size and number of filters vary from layer to layer</li>
										<li>output: model able to predict label given unseen data</li>
									</ul>
							</div>
						</section>


						<section>
							<h4>Machine Learning</h4>
							<div class="fitem">
									<ul>
										<li>Deep convolutional ML learns the features of images as weights of Neural Networks </li>
										<li>proven fast for seismic signal analysis (e.g. Kriegerowski et al., 2019) </li>
										<li>recent advances allow for distributions of weights </li>
									</ul>
							</div>
							<img src="figures/cnn-bnn.svg" style="height: 8em;"/>
						</section>



				</section>


											<section>
												<section id="InputTraining">
													<h5>Training Input</h5>
												</section>
												<section >
													<div class="fitem">
															<ul>
																<li>training on synthetic waveforms from a volume of potential source locations</li>
																<li>advantage: controll over source and targets</li>
																<li>using pre-calculated Green's function stores (<a href="https://pyrocko.org">Pyrocko</a> and QSEIS)</li>
															</ul>
													</div>
													<img src="figures/gf_store.svg" style="height: 6em;"/>
														<aside class="notes">
															<p>As input for we use synthetic displacement waveform data calculated for specific earthquake source and for all considered stations and E, N and Z components. 
For the fast forward calculations of the synthetic waveforms we use pre-calculated Green’s functions stores. They are based on a 1-D velocity model and using the Pyrocko software framework \citep{heimann2017pyrocko, heimann2019python} and the reflectivity-type wavenumber integration method code QSEIS \citep{wang1999simple}. We calculate three different Green's function stores, one based on a 1-D velocity model for the entire Mojave Region used by the USGS and the SCEDC,</p>
														</aside>
												</section>



												<section>
													<div class="fitem">
															<ul>
																<li>CNN optimised for images</li>
																<li>Amplitudes vary for different sources-distances</li>
																&#x2192;no direct use of the waveform arrays for training

															</ul>
													</div>
													<img src="figures/input0.svg" style="height: 12em;"/>
													<aside class="notes">
														<p> filter between 1 and 5.4 Hz; cutout</p>
													</aside>
												</section>

												<section>
													<div class="fitem">
															<ul>
																<li>filter waveforms (bandpass 0.8-5.4 Hz)</li>
																<li>cut 1s before first phase onset</li>
																																<li>cut 4s after first phase onset</li>

															</ul>
																				<aside class="notes">
																	<p> We learn our neural networks on the pure synthetic waveforms and do not add noise to the synthetic waveforms, because the characteristics of the noise would be learned as well.
A triangular source time function is assumed</p>
																</aside>
													</div>

												</section>

												<section>
													<h4>Normalized input for a single earthquake source</h4>

													<img src="figures/input.svg" style="height: 12em;"/>
												</section>
											</section>

												<section>
													<section id="Labels">
														<h5>Labels</h5>
													</section>


													<section>
													<div class="fbox" style="vertical-align: top; width: 100%;">
			                        <div class="fitem">
			                            <h4>Using the Lune paramterziation of the MT</h4>
																	<ul>
																		<li>only 5 unique paramters (&kappa;, &sigma;, h, w, v)</li>
																		<li>cartesian coordinate system</li>
																		<li>v=0 and w=0 -> isotropic source</li>
																		<li> no scaling with &rho; because of normalized input</li>
																	</ul>
			                                <img src="figures/lune.svg" style="height: 8em;"/>
			                        </div>
																		<aside class="notes">
																<p>For each set of waveforms forming an input image we want to have a fixed set of parameters assigned to the specifics of the causative source. This are the so called labels we want our networks to learn. 
The moment tensor description with six independent components \citep{madariaga2007seismic} normally used to describe seismic sources but is not unique. It has been shown that only five unique independent parameters are needed when using spherical coordinates on the unit sphere of the fundamental lune description of the moment tensor to describe all possible sources \citep{tape2015uniform, tape2012geometric}. This fundamental lune parameterzisation of the moment tensor clearly separates the radiation pattern from the source orientation. It also uses cartesian coordinates and is therefore suitable to be sampled by typical machine learning approaches. The five independent parameters (see also supp. Table 1) describing the source in terms of the fundamental lune are: $\kappa$ as the strike angle equivalent, $\sigma$ as the rake angle equivalent of moment tensor slip angle, h as dip angle equivalent and v and w as the lune latitude and co-longitude defining the non-isotropic components. </p>
																</aside>
												</section>

											</section>


				<section>
					<section id="BNN">
						<h5>BNN</h5>
					</section>

					<section>
						<h4>Network design </h4>
						<div class="fitem">
								<ul>
								<li>All models are wrong, but some are useful</li>
									<li>Train our networks to say: "I dont know"</li>
									<li>robust estimations necessary for operational hazard frameworks</li>
								</ul>
						</div>
						<aside class="notes">
							<p> Geophyiscs always at the forefront of estimation of model robustnes. Our goal is to use a simple as possible neuronal network to avoid overfitting and allow for easy interpretation of the individual learning steps.</p>
						</aside>
					</section>


								<section>
									<h4>Network design - keep it simple</h4>
									<div class="fitem">
											<ul>
											<li>loss function: neg. log-likeliehood</li>
												<li>optimizer: Adam, RELu activations</li>
												<li>Flipout layer (Wen, 2018), tfp</li>
											</ul>
									</div>
									<img src="figures/bnn_presentation_full_all.svg" style="height: 8em;"/>
																			<aside class="notes">
											<p> An overview of the network design is sketched in Fig. \,\ref{fig:network},a and is similar in rationale to \citet{kriegerowski2019deep}. We use three 2-D convolutional flipout layers. The two first layer are sensitive to the information over time only. The first layer is very fine has 8 filters and a 1 by 2 kernel and the second layer has 10 filters and a 1 by 30 kernel. The last 2-D convolutional flipout layer collects information over the station components with 12 filters and a 3 by 1 kernel. We use a dropout of 0.2 between convolutional layers to robustly handle data errors and missing waveform data.
We downsample the data with a 2-D pooling layer with a 3 by 4 kernel (example activations see Fig. \,\ref{fig:network},c) before flattening the data into a vector and feeding them into a fully connected dense flipout layer. All flipout layers are activated using a Rectified Linear Unit function</p>
											<p>flipout layer creates a convolution kernel that is convolved (actually cross-correlated) with the layer input to produce a tensor of outputs. It may also include a bias addition and activation function on the outputs. It assumes the kernel and/or bias are drawn from distributions.</p>
											<p> It uses the Flipout estimator [(Wen et al., 2018)][1], which performs a Monte Carlo approximation of the distribution integrating over the kernel and bias</p>		
											<p>Upon being built, this layer adds losses (accessible via the losses property) representing the divergences of kernel and/or bias surrogate posteriors and their respective priors. </p>
									</aside>
								</section>



								<section>
									<h4>Blackbox? Example activations</h4>
									<img src="figures/bnn_presentation_full_-1.png" style="height: 14em;"/>
								</section>

								<section>
									<h4>Blackbox? Example activations</h4>
									<img src="figures/bnn_presentation_full_0.png" style="height: 14em;"/>
								</section>

								<section>
									<h4>Blackbox? Example activations</h4>
									<img src="figures/bnn_presentation_full_1.png" style="height: 14em;"/>
								</section>


								<section>
									<h4>Blackbox? Example activations</h4>
									<img src="figures/bnn_presentation_full_2.png" style="height: 14em;"/>
								</section>

								<section>
									<h4>Blackbox? Example activations</h4>
									<img src="figures/bnn_presentation_full_3.png" style="height: 14em;"/>
								</section>

								<section>
									<h4>Blackbox? Example activations</h4>
									<img src="figures/bnn_presentation_full_4.png" style="height: 14em;"/>
								</section>


								<section>
									<h4>Blackbox? Example activations</h4>
									<img src="figures/bnn_presentation_full_5.png" style="height: 14em;"/>
								</section>

							<section>
								<h4>Variational inference (Bayesian) Machine Learning approach</h4>
								<img src="figures/scheme_rework.svg" style="height: 12em;"/>
								<aside class="notes">
											<p> The moment magnitude is not needed as prior information beforehand for our approach, as all waveforms are normalized. The magnitude of the earthquake can be readily estimated by other methods and approaches \citep{van2020automated}. As a prior knowledge for our inputs the approximate earthquakes location is needed. This has been shown to be deliverable fast by other already established machine learning based algorithms \citep{kriegerowski2019deep,mousavi2020earthquake}. </p>
									<p>The probabilistic output of the evaluation of input into an individual BNN allows us to combine inferences. This easily allows us to consider several likely locations and onset times of the earthquake source. 

We consider a location error in horizontal and vertical direction. For each grid point within the error ellipse around the given centroid location we evaluate the respective model with the given input. Note that for each grid point the waveform input is cut differently according to the theoretical arrival times. We perform one evaluation for each grid point and each model with a single input if no timing error exists (see sketch in Fig.\,\ref{fig:scheme}). 

If a error in the onset time is given we simply shift the predicted theoretical arrival times by the expected error.</p>	
								</aside>
							</section>
						</section>


								<section>
									<section id="Ridgecrest">
										<h5>Test and validation with unseen data of the the 2019 Ridgecrest sequence</h5>
									</section>
									<section  data-background-video="figures/ridgecrest_sequence.mp4" data-background-video-muted>
									</section>
									<section data-background-video="figures/stations_grid_zoom.mp4" data-background-video-muted>
																							<aside class="notes">
											<p>Our source location grid (Fig. ~\ref{fig:area},b) extents horizontally roughly 11 by 11\,km, with a step size of 1.5\,km. The vertical extent ranges from 2\,km to 10\,km depth, in 2 \,km steps.</p>
									</aside>
									</section>
                </section>

										<section>
											<section  id="MomentTensor">
												<h5>Comparison of predictions and 8 SCEDC catalog moment tensors</h5>
											</section>
											<section data-background-video="figures/mts.mp4" data-background-video-muted>
														<aside class="notes">
															<p> 8 full moment tensor solutions from SCEDC are available in the region of interest between July 2019 and December 2020, as well as 198 pure double-couple focal mechanism solutions (Fig. \,\ref{fig:area},b). For this real and unseen waveform data we compare the results of the estimates of our Machine Learning based approach with the focal mechanism and the moment tensors as determined by USGS and SCEDC \citep{hutton2010earthquake}. We therefore validate our approach with unseen data and with independently determined mechanisms and show that we can produce similar source mechanism estimates of the routine SCEDC framework \citep{hauksson2007regional, jordan2003scec} in a few seconds processing time per earthquake. </p>
													</aside>
											</section>

											<section>
											  <h5>Omega angle distance measure</h5>
											  \[\begin{aligned}
												d = \frac{1}{2}\Bigg[1-\frac{U_{1}\cdot U_{2}}{||U_{1}||||U_{2}||}\Bigg] = \frac{1}{2}\Bigg[1-\frac{\sum U_{1_{ij}}\cdot U_{2_{ij}}}{(\sum U^2_{1_{ij}})^{\frac{1}{2}} (U^2_{2_{ij}})^{\frac{1}{2}}}\Bigg]
											  \end{aligned} \]
												<img src="figures/omega_angle.svg" style="height: 8em;"/>
												<p>after Tape and Tape, 2012</p>
												
														<p>To asses the similarity between the predicted and cataloged moment tensor we use the omega angle \citep{tape2012angle} measure. The omega angle has the advantage that focal mechanisms with opposite polarities are considered most dissimilar in contrast to other measures \citep{cesca2014seismicity}. We use it in a normalized way in a distance definition \citep{cesca2014seismicity} between 0 and 1, meaning an identical seismic radiation pattern and opposite radiation pattern respectively between the two compared moment tensors. </p>					<aside class="notes">
													</aside>
											</section>


											<section>
												<video data-autoplay src="figures/mts_time_figs/output.webm"></video>
											</section>

                    </section>

												<section>
													<section  id="dcs">
														<h5>Comparison of predictions and 196 SCEDC catalog focal mechanisms (Mw 2.7 to 4.5)</h5>
													</section>
													<section  data-background-video="figures/dcs.mp4" data-background-video-muted>
													</section>

													<section>
														<img src="figures/dc_hist_no_vw.svg" style="height: 8em;"/>
													</section>

													<section>
														<img src="figures/dc_hist_mag.svg" style="height: 8em;"/>
													</section>

		                    </section>

												<section>
												<section id="conclusions">
													<h4>Conclusions</h4>
													<div class="fitem">
															<ul>
																<li>ML can be applied to determine full MTs</li>
																	<li class="grayout">sucessfully reproduce indepently determined MTs for subset of Ridgecrest earthquakes</li>
															</ul>
													</div>
												</section>
												<section>

													<h4>Conclusions</h4>
													<div class="fitem">
															<ul>
																<ul>
																	<li class="grayout"> ML can be applied to determine full MTs</li>
																		<li>sucessfully reproduce indepently determined MTs for subset of Ridgecrest earthquakes</li>
																</ul>
															</ul>
													</div>
												</section>
												<section>

													<h4>General takeaway</h4>
													<div class="fitem">
															<ul>
																<li> (Bayesian) Variational Machine Learning can be useful in geophysics</li>
																<li class="grayout">ML != black box (if you do not make it one)</li>
															</ul>
													</div>

												</section>

												<section>

													<h4>General takeaway</h4>
													<div class="fitem">
															<ul>
																<li class="grayout"> (Bayesian) Variational ML can be useful in geophysics</li>
																<li >ML != black box (if you do not make it one)</li>
															</ul>
													</div>

												</section>

												<section>

													<video data-autoplay src="figures/ridgecrest_sequence.mp4"></video>

													Thank you!
													<div class="links">
														<img src="figures/bgr.jpg" style="height: 1.5em;"/>
													</div>
												</section>
											</section>

											<section>
												<section id="appendix">
													<h5>Appendix</h5>

												</section>
												<section>
													<img src="figures/velocity_models.svg" style="height: 8em;"/>
												</section>

												<section>
												<div class="fbox" style="vertical-align: top; width: 100%;">
														<div class="fitem">
																<h4>For each potential source location in the grid:</h4>
																<ul>
																<li>steps: 0.1&pi; for &kappa;, 0.2 for &sigma;, h and w and 0.02 for v</li>
																	<li>171.600 waveform datasets</li>
																	<li>196 gridpoints for the test dataset</li>
																</ul>
														</div>
											</section>

												<section class="narrow" data-markdown>
																<script type="text/template">
														| Parameter       | Interpretation           | Bounds  |
														| :-------------: |:-------------:| :-----:|
														| w      | Lune latitude delta transformed to grid | -3/8pi <= w <=3/8pi |
														| v      | Lune co-longitude transformed to grid      |   -1/3 <= v <= 1/3 |
														| kappa | Strike angle equivalent of moment tensor plane     |    0 <= kappa <= 2pi |
														| sigma | Rake angle equivalent of moment tensor slip angle.     |    -pi/2 <= sigma <= pi/2 |
														| h | Dip angle equivalent of moment tensor plane     |    0 <= h <= 1 |
													</script>
												</section>

												<section>
													<img src="figures/dc_hist_vw.svg" style="height: 8em;"/>
												</section>


									<section>
										<img src="figures/dc_1.svg" style="height: 8em;"/>
										<img src="figures/dc_2.svg" style="height: 8em;"/>
										<img src="figures/dc_3.svg" style="height: 8em;"/>

									</section>


									<section>
										<img src="figures/fits.svg" style="height: 17em;"/>


									</section>

								</section>


			</div>
		</div>

		<script src="dist/reveal.js"></script>
		<script src="plugin/notes/notes.js"></script>
		<script src="plugin/markdown/markdown.js"></script>
		<script src="plugin/highlight/highlight.js"></script>
		<script>
			// More info about initialization & config:
			// - https://revealjs.com/initialization/
			// - https://revealjs.com/config/
			Reveal.initialize({
				hash: true,

				// Learn about plugins: https://revealjs.com/plugins/
				plugins: [ RevealMarkdown, RevealHighlight, RevealNotes ]
			});
		</script>
	</body>
</html>
